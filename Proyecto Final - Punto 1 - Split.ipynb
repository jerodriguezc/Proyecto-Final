{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final - Deep Learning y Redes Neuronales\n",
    "\n",
    "MIIA4406 - 201819 - Universidad de los Andes\n",
    "### Integrantes:\n",
    "- Jorge Eduardo Rodriguez Cardozo - 200711501\n",
    "- German Augusto Carvajal Murcia -  201313516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/germancarvajal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/germancarvajal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "inicio=time()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score,make_scorer,accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import unidecode\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline\n",
    "path = os.getcwd()\n",
    "dataTraining = pd.read_csv(os.path.join(path, 'data', 'dataTraining.csv'), encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█'):\n",
    "    import sys\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    sys.stdout.write('\\r %s |%s| %s%% %s' % (prefix, bar, percent, suffix))\n",
    "    sys.stdout.flush()\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_size=(256,160) #Size of the images to import\n",
    "Gray=True #True if the images to load are in grayscale, False for RGB encoding\n",
    "words= 2000 #Number of text features to consider in the algorithm\n",
    "usePCA = (False, 1000) #Arg1: True for using PCA over the images data for dimensionality reduction, Arg2: Number of principal components to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def split_into_lemmas(text):\n",
    "    text = unidecode.unidecode(text.lower())\n",
    "    words = text.split()\n",
    "    nopunc = [char for char in words if char not in string.punctuation]\n",
    "    clean_mess = [word for word in nopunc if word not in stopwords.words('english')]\n",
    "    return [wordnet_lemmatizer.lemmatize(word).encode('ascii') for word in clean_mess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text input size:  (7895, 2000)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1, 2), max_features=words, analyzer=split_into_lemmas,binary=False)\n",
    "X_txt = vect.fit_transform(dataTraining['plot'])\n",
    "print('Text input size: ',X_txt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Progress: |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "X_image=np.empty((dataTraining.shape[0],(Img_size[0]*Img_size[1]*(3-2*Gray))))\n",
    "N=dataTraining.shape[0]\n",
    "n=0\n",
    "for i in dataTraining.index:\n",
    "    img = load_img(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg'),target_size=Img_size,grayscale=Gray)  # this is a PIL image\n",
    "    x = img_to_array(img).flatten()  # this is a Numpy array with shape (Img_size[0]*Img_size[1]*(3-2*I(Gray)))\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    X_image[n]=x\n",
    "    n=n+1\n",
    "    printProgressBar(n,N,prefix = 'Progress:', suffix = 'Complete', length = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No PCA\n"
     ]
    }
   ],
   "source": [
    "if usePCA[0]:\n",
    "    pca=PCA()\n",
    "    pca.fit(X_image)\n",
    "    plt.figure(1, figsize=(10, 5))\n",
    "    plt.xlabel('Num factors')\n",
    "    plt.ylabel('Explained variance')\n",
    "    plt.axvline(x=usePCA[1],color='red')\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    pcaT=PCA(usePCA[1])\n",
    "    X_image=pcaT.fit_transform(X_image)\n",
    "else:\n",
    "    print('No PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  (7895, 42960)\n",
      "Labels:  (7895, 24)\n"
     ]
    }
   ],
   "source": [
    "X=np.concatenate((X_txt.toarray(),X_image),axis=1)\n",
    "Y_lab=dataTraining['genres']\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(pd.Series(Y_lab).map(lambda x: eval(x)))\n",
    "print('Features: ',X.shape)\n",
    "print('Labels: ',Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int,X_test,Y_int,Y_test=train_test_split(X,Y,test_size=0.1,random_state=123)\n",
    "Index_train,Index_validation=train_test_split(range(X_int.shape[0]),test_size=0.2/0.9,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig:  (5526, 42960) (5526, 24)\n",
      "Validation:  (1579, 42960) (1579, 24)\n",
      "Test:  (790, 42960) (790, 24)\n"
     ]
    }
   ],
   "source": [
    "print('Trainig: ',X_int[Index_train].shape,Y_int[Index_train].shape)\n",
    "print('Validation: ',X_int[Index_validation].shape,Y_int[Index_validation].shape)\n",
    "print('Test: ',X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action</td>\n",
       "      <td>884</td>\n",
       "      <td>283</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>705</td>\n",
       "      <td>216</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animation</td>\n",
       "      <td>182</td>\n",
       "      <td>54</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biography</td>\n",
       "      <td>248</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>2166</td>\n",
       "      <td>591</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crime</td>\n",
       "      <td>1019</td>\n",
       "      <td>279</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>293</td>\n",
       "      <td>90</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drama</td>\n",
       "      <td>2793</td>\n",
       "      <td>784</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Family</td>\n",
       "      <td>489</td>\n",
       "      <td>129</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>500</td>\n",
       "      <td>127</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Film-Noir</td>\n",
       "      <td>116</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>History</td>\n",
       "      <td>179</td>\n",
       "      <td>58</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Horror</td>\n",
       "      <td>656</td>\n",
       "      <td>184</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Music</td>\n",
       "      <td>236</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Musical</td>\n",
       "      <td>202</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>516</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>News</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Romance</td>\n",
       "      <td>1352</td>\n",
       "      <td>361</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>503</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Short</td>\n",
       "      <td>62</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sport</td>\n",
       "      <td>168</td>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>1404</td>\n",
       "      <td>410</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>War</td>\n",
       "      <td>236</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Western</td>\n",
       "      <td>160</td>\n",
       "      <td>51</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Class Train Validation Test\n",
       "0        Action   884        283  136\n",
       "1     Adventure   705        216  103\n",
       "2     Animation   182         54   24\n",
       "3     Biography   248         90   35\n",
       "4        Comedy  2166        591  289\n",
       "5         Crime  1019        279  149\n",
       "6   Documentary   293         90   36\n",
       "7         Drama  2793        784  388\n",
       "8        Family   489        129   64\n",
       "9       Fantasy   500        127   80\n",
       "10    Film-Noir   116         31   21\n",
       "11      History   179         58   36\n",
       "12       Horror   656        184  114\n",
       "13        Music   236         56   49\n",
       "14      Musical   202         37   32\n",
       "15      Mystery   516        168   75\n",
       "16         News     5          1    1\n",
       "17      Romance  1352        361  179\n",
       "18       Sci-Fi   503        148   72\n",
       "19        Short    62         23    7\n",
       "20        Sport   168         57   36\n",
       "21     Thriller  1404        410  210\n",
       "22          War   236         67   45\n",
       "23      Western   160         51   26"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.transpose([mlb.classes_,Y_int[Index_train].sum(axis=0),Y_int[Index_validation].sum(axis=0),Y_test.sum(axis=0)]),columns=['Class','Train','Validation','Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_fold=np.empty(X_int.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Index_train:\n",
    "    validation_fold[i]=-1\n",
    "for i in Index_validation:\n",
    "    validation_fold[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "ps = PredefinedSplit(validation_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation AUC: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "#Scorer\n",
    "my_roc=make_scorer(roc_auc_score,greater_is_better=True,needs_proba=True,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 40.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV for RandomForest took 2738.29 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation AUC: 0.632 (std: 0.000)\n",
      "Parameters: {'estimator__bootstrap': False, 'estimator__criterion': 'entropy', 'estimator__max_depth': 6, 'estimator__max_features': 3, 'estimator__n_estimators': 94}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation AUC: 0.626 (std: 0.000)\n",
      "Parameters: {'estimator__bootstrap': False, 'estimator__criterion': 'gini', 'estimator__max_depth': 7, 'estimator__max_features': 9, 'estimator__n_estimators': 199}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation AUC: 0.614 (std: 0.000)\n",
      "Parameters: {'estimator__bootstrap': True, 'estimator__criterion': 'entropy', 'estimator__max_depth': 6, 'estimator__max_features': 10, 'estimator__n_estimators': 106}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build a classifier\n",
    "clf1 = OneVsRestClassifier(RandomForestClassifier())\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"estimator__n_estimators\": sp_randint(10, 200),\n",
    "              \"estimator__max_depth\": sp_randint(3, 10),\n",
    "              \"estimator__max_features\": sp_randint(1, 11),\n",
    "              \"estimator__bootstrap\": [True, False],\n",
    "              \"estimator__criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search=10\n",
    "random_search1 = RandomizedSearchCV(clf1, param_distributions=param_dist,cv=ps,n_iter=n_iter_search,return_train_score=True,verbose=1,scoring=my_roc,random_state=123)\n",
    "\n",
    "#Report results\n",
    "start = time()\n",
    "random_search1.fit(X_int, Y_int)\n",
    "print(\"RandomizedSearchCV for RandomForest took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62089490387799839"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1=OneVsRestClassifier(RandomForestClassifier(bootstrap=random_search1.best_params_['estimator__bootstrap'],criterion=random_search1.best_params_['estimator__criterion'],\n",
    "                                               max_depth=random_search1.best_params_['estimator__max_depth'],max_features=random_search1.best_params_['estimator__max_features'],\n",
    "                                               n_estimators=random_search1.best_params_['estimator__n_estimators']))\n",
    "clf1.fit(X_int,Y_int)\n",
    "Y_pred=clf1.predict_proba(X_test)\n",
    "roc_auc_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Progress: |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "dataTesting = pd.read_csv(os.path.join(path, 'data', 'dataTesting.csv'), encoding='UTF-8', index_col=0)\n",
    "X_image_pred=np.empty((dataTesting.shape[0],(Img_size[0]*Img_size[1]*(3-2*Gray))))\n",
    "N=dataTesting.shape[0]\n",
    "n=0\n",
    "for i in dataTesting.index:\n",
    "    img = load_img(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg'),target_size=Img_size,grayscale=Gray)  # this is a PIL image\n",
    "    x = img_to_array(img).flatten()  # this is a Numpy array with shape (Img_size[0]*Img_size[1]*(3-2*I(Gray)))\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    X_image_pred[n]=x\n",
    "    n=n+1\n",
    "    printProgressBar(n,N,prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "X_txt_pred = vect.transform(dataTesting['plot'])\n",
    "if usePCA[0]:\n",
    "    X_image_pred=pcaT.transform(X_image_pred)\n",
    "X_pred=np.concatenate((X_txt_pred.toarray(),X_image_pred),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred1=pd.DataFrame(clf1.predict_proba(X_pred),columns=['p_'+s for s in mlb.classes_],index=dataTesting.index)\n",
    "pred1.to_csv(path_or_buf ='OvsR_RF_Split_Calib.csv',index_label='ID',encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time took 3901.89 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Total execution time took %.2f seconds\" % ((time() - inicio)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
