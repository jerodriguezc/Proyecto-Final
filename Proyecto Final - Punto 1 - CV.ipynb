{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final - Deep Learning y Redes Neuronales\n",
    "\n",
    "MIIA4406 - 201819 - Universidad de los Andes\n",
    "### Integrantes:\n",
    "- Jorge Eduardo Rodriguez Cardozo - 200711501\n",
    "- German Augusto Carvajal Murcia -  201313516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "inicio=time()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score,make_scorer,accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import unidecode\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline\n",
    "path = os.getcwd()\n",
    "dataTraining = pd.read_csv(os.path.join(path, 'data', 'dataTraining.csv'), encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ'):\n",
    "    import sys\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    sys.stdout.write('\\r %s |%s| %s%% %s' % (prefix, bar, percent, suffix))\n",
    "    sys.stdout.flush()\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_size=(256,160) #Size of the images to import\n",
    "Gray=True #True if the images to load are in grayscale, False for RGB encoding\n",
    "words= 2000 #Number of text features to consider in the algorithm\n",
    "usePCA = (False, 1000) #Arg1: True for using PCA over the images data for dimensionality reduction, Arg2: Number of principal components to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def split_into_lemmas(text):\n",
    "    text = unidecode.unidecode(text.lower())\n",
    "    words = text.split()\n",
    "    nopunc = [char for char in words if char not in string.punctuation]\n",
    "    clean_mess = [word for word in nopunc if word not in stopwords.words('english')]\n",
    "    return [wordnet_lemmatizer.lemmatize(word).encode('ascii') for word in clean_mess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1, 2), max_features=words, analyzer=split_into_lemmas,binary=False)\n",
    "X_txt = vect.fit_transform(dataTraining['plot'])\n",
    "print('Text input size: ',X_txt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image=np.empty((dataTraining.shape[0],(Img_size[0]*Img_size[1]*(3-2*Gray))))\n",
    "N=dataTraining.shape[0]\n",
    "n=0\n",
    "for i in dataTraining.index:\n",
    "    img = load_img(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg'),target_size=Img_size,grayscale=Gray)  # this is a PIL image\n",
    "    x = img_to_array(img).flatten()  # this is a Numpy array with shape (Img_size[0]*Img_size[1]*(3-2*I(Gray)))\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    X_image[n]=x\n",
    "    n=n+1\n",
    "    printProgressBar(n,N,prefix = 'Progress:', suffix = 'Complete', length = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if usePCA[0]:\n",
    "    pca=PCA()\n",
    "    pca.fit(X_image)\n",
    "    plt.figure(1, figsize=(10, 5))\n",
    "    plt.xlabel('Num factors')\n",
    "    plt.ylabel('Explained variance')\n",
    "    plt.axvline(x=usePCA[1],color='red')\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    pcaT=PCA(usePCA[1])\n",
    "    X_image=pcaT.fit_transform(X_image)\n",
    "else:\n",
    "    print('No PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((X_txt.toarray(),X_image),axis=1)\n",
    "Y_lab=dataTraining['genres']\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(pd.Series(Y_lab).map(lambda x: eval(x)))\n",
    "print('Features: ',X.shape)\n",
    "print('Labels: ',Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.transpose([mlb.classes_,Y_train.sum(axis=0),Y_test.sum(axis=0)]),columns=['Class','Train','Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h=pd.DataFrame(np.transpose([mlb.classes_,Y_train.sum(axis=0)]),columns=['Class','Count'])\n",
    "classes_for_rebalance=h[h['Count']<0.05*Y_train.shape[0]].sort_values('Count').index.tolist()\n",
    "h[h['Count']<0.05*Y_train.shape[0]].sort_values('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OverSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X[y == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y == 0)[0]), axis=0)\n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA=np.concatenate((X_train,Y_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_res=DATA\n",
    "Y_res=Y_train\n",
    "for i in classes_for_rebalance:\n",
    "    X_res,Y_res=OverSampling(X_res,Y_res[:,i],target_percentage=0.05,seed=123)\n",
    "    Y_res=X_res[:,(X_train.shape[1]):]\n",
    "    print('Balanced class: ',mlb.classes_[i],' - Correct ouput: ',np.array_equal(Y_res[:,i],X_res[:,(X_train.shape[1]+i)]),' - New (X)(Y): ',X_res.shape,Y_res.shape)\n",
    "X_res=X_res[:,:(X_train.shape[1])]\n",
    "np.random.seed(123)\n",
    "idx=np.arange(X_res.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "Y_res=Y_res[idx]\n",
    "X_res=X_res[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.transpose([mlb.classes_,Y_res.sum(axis=0)]),columns=['Class','Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features: ',X_res.shape)\n",
    "print('Labels: ',Y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation AUC: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "#Scorer\n",
    "my_roc=make_scorer(roc_auc_score,greater_is_better=True,needs_proba=True,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "clf1 = OneVsRestClassifier(RandomForestClassifier())\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"estimator__n_estimators\": sp_randint(10, 200),\n",
    "              \"estimator__max_depth\": sp_randint(3, 10),\n",
    "              \"estimator__max_features\": sp_randint(1, 11),\n",
    "              \"estimator__bootstrap\": [True, False],\n",
    "              \"estimator__criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search=10\n",
    "folds=5\n",
    "random_search1 = RandomizedSearchCV(clf1, param_distributions=param_dist,cv=folds,n_iter=n_iter_search,return_train_score=True,scoring=my_roc,random_state=123)\n",
    "\n",
    "#Report results\n",
    "start = time()\n",
    "random_search1.fit(X_res, Y_res)\n",
    "print(\"RandomizedSearchCV for RandomForest took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=OneVsRestClassifier(RandomForestClassifier(bootstrap=random_search1.best_params_['estimator__bootstrap'],criterion=random_search1.best_params_['estimator__criterion'],\n",
    "                                               max_depth=random_search1.best_params_['estimator__max_depth'],max_features=random_search1.best_params_['estimator__max_features'],\n",
    "                                               n_estimators=random_search1.best_params_['estimator__n_estimators']))\n",
    "clf1.fit(X_res,Y_res)\n",
    "Y_pred=clf1.predict_proba(X_test)\n",
    "roc_auc_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTesting = pd.read_csv(os.path.join(path, 'data', 'dataTesting.csv'), encoding='UTF-8', index_col=0)\n",
    "X_image_pred=np.empty((dataTesting.shape[0],(Img_size[0]*Img_size[1]*(3-2*Gray))))\n",
    "N=dataTesting.shape[0]\n",
    "n=0\n",
    "for i in dataTesting.index:\n",
    "    img = load_img(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg'),target_size=Img_size,grayscale=Gray)  # this is a PIL image\n",
    "    x = img_to_array(img).flatten()  # this is a Numpy array with shape (Img_size[0]*Img_size[1]*(3-2*I(Gray)))\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    X_image_pred[n]=x\n",
    "    n=n+1\n",
    "    printProgressBar(n,N,prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "X_txt_pred = vect.transform(dataTesting['plot'])\n",
    "if usePCA[0]:\n",
    "    X_image_pred=pcaT.transform(X_image_pred)\n",
    "X_pred=np.concatenate((X_txt_pred.toarray(),X_image_pred),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred1=pd.DataFrame(clf1.predict_proba(X_pred),columns=['p_'+s for s in mlb.classes_],index=dataTesting.index)\n",
    "pred1.to_csv(path_or_buf ='OvsR_RF_CV5_Calib.csv',index_label='ID',encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total execution time took %.2f seconds\" % ((time() - inicio)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
